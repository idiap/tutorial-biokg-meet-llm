{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3p1AE72yXmiX",
        "hai06SuoXr-8",
        "vA05jsOJbJVo",
        "6LI6pxSeXz4E",
        "odtKwunJX4ub",
        "Ek2gJSN9w68j",
        "0guxw1geBiW2",
        "g8tcOhhRYS6E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recogniyion (NER) and Relation Extraction (RE)"
      ],
      "metadata": {
        "id": "EBlKfHAqOuUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings"
      ],
      "metadata": {
        "id": "-GIxwSaGq8__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to install dspy\n",
        "!pip install backoff\n",
        "!pip install dspy"
      ],
      "metadata": {
        "id": "-6fdxmaZO_Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "745b735f-72e9-4329-fe34-5e5e0f65da49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n",
            "Collecting dspy\n",
            "  Downloading dspy-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: backoff>=2.2 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.2.1)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (1.5.1)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (1.99.8)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (2024.11.6)\n",
            "Collecting ujson>=5.8.0 (from dspy)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.32.3)\n",
            "Collecting optuna>=3.4.0 (from dspy)\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.11.7)\n",
            "Collecting magicattr>=0.1.6 (from dspy)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.64.0 (from dspy)\n",
            "  Downloading litellm-1.75.7-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.0 (from dspy)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy)\n",
            "  Downloading json_repair-0.49.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from dspy) (9.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from dspy) (4.10.0)\n",
            "Collecting asyncer==0.0.8 (from dspy)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from dspy) (13.9.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (2.0.2)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from dspy) (3.5.0)\n",
            "Collecting gepa==0.0.4 (from gepa[dspy]==0.0.4->dspy)\n",
            "  Downloading gepa-0.0.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets>=2.14.6 in /usr/local/lib/python3.11/dist-packages (from gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (4.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->dspy) (4.14.1)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (3.12.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (8.2.1)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (4.25.0)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm>=1.64.0->dspy)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (0.11.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.64.0->dspy) (0.21.4)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=0.28.1->dspy) (0.10.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.4.0->dspy)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (2.0.43)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna>=3.4.0->dspy) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dspy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->dspy) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2.2.2)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (0.34.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy) (3.2.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (1.17.0)\n",
            "Downloading dspy-3.0.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.0/259.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading gepa-0.0.4-py3-none-any.whl (35 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.49.0-py3-none-any.whl (26 kB)\n",
            "Downloading litellm-1.75.7-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magicattr, ujson, python-dotenv, json-repair, diskcache, colorlog, asyncer, alembic, optuna, litellm, gepa, dspy\n",
            "Successfully installed alembic-1.16.4 asyncer-0.0.8 colorlog-6.9.0 diskcache-5.6.3 dspy-3.0.1 gepa-0.0.4 json-repair-0.49.0 litellm-1.75.7 magicattr-0.1.6 optuna-4.4.0 python-dotenv-1.1.1 ujson-5.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import json\n",
        "import random\n",
        "import requests\n",
        "import hashlib\n",
        "import backoff\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from typing import List\n",
        "from collections import defaultdict\n",
        "from urllib3.util.retry import Retry\n",
        "from requests.adapters import HTTPAdapter\n",
        "from langchain_core.documents.base import Document\n"
      ],
      "metadata": {
        "id": "JD7w6tMvO1oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PubTator Client for NER / RE"
      ],
      "metadata": {
        "id": "6-R5QWepPLG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubTator Client Utility Class"
      ],
      "metadata": {
        "id": "H0wLSggWXTYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUFHBHVCf2Wy"
      },
      "outputs": [],
      "source": [
        "class PubTatorClient:\n",
        "    def __init__(self, base_url: str, max_retries: int = 3):\n",
        "        self.session = requests.Session()\n",
        "        self.base_url = base_url\n",
        "        # Configure retry strategy\n",
        "        retry_strategy = Retry(\n",
        "            total=max_retries,\n",
        "            backoff_factor=1,\n",
        "            status_forcelist=[429, 500, 502, 503, 504],\n",
        "        )\n",
        "\n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        self.session.mount(\"http://\", adapter)\n",
        "        self.session.mount(\"https://\", adapter)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    @backoff.on_exception(\n",
        "        backoff.expo, requests.exceptions.RequestException, max_tries=3\n",
        "    )\n",
        "    def _fetch_publications(self, pmids: List[str]) -> dict:\n",
        "        params = {\"pmids\": \",\".join(pmids)}\n",
        "\n",
        "        response = self.session.get(self.base_url, params=params, timeout=300)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "\n",
        "    def _parse(self, response: dict):\n",
        "        doc_text = \"\\n\".join([passage[\"text\"] for passage in response[\"passages\"]])\n",
        "        pmid = response[\"id\"]\n",
        "        doc = {\"pmid\": pmid, \"text\": doc_text}\n",
        "        biomedical_entities = []\n",
        "        biomedical_relations = []\n",
        "        # To save the accession number and map back the entities in the relations.\n",
        "        accession_dict = {}\n",
        "\n",
        "        for passage in response[\"passages\"]:\n",
        "            annotations = passage[\"annotations\"]\n",
        "            for annotation in annotations:\n",
        "                # For simplicity, we are only going to keep the 'valid' annotations.\n",
        "                if not annotation['infons'].get('valid', False):\n",
        "                  continue\n",
        "                span = annotation[\"text\"]\n",
        "                name = annotation[\"infons\"][\"name\"]\n",
        "                annot_type = annotation[\"infons\"][\"type\"]\n",
        "                identifier = annotation[\"infons\"][\"identifier\"]\n",
        "                accession = annotation[\"infons\"][\"accession\"]\n",
        "                accession_dict[accession] = {\"type\": annot_type, \"identifier\": identifier}\n",
        "\n",
        "                # Sometimes, there can be an entry for identifier, but it is actaully not determined and refer the '-'.\n",
        "                if identifier == \"-\":\n",
        "                    identifier = hashlib.sha256(span.encode(\"utf-8\")).hexdigest()\n",
        "                biomedical_entities.append({\n",
        "                    \"label\": annot_type,\n",
        "                    \"span\": span,\n",
        "                    \"name\": name,\n",
        "                    \"id\": identifier,\n",
        "                    \"pmid\": pmid\n",
        "                })\n",
        "        for relation_info in response['relations_display']:\n",
        "\n",
        "          rel_type, s_accession_id, o_accession_id = relation_info['name'].split('|')\n",
        "          source = accession_dict.get(s_accession_id, {})\n",
        "          target = accession_dict.get(o_accession_id, {})\n",
        "          if not source or not target:\n",
        "            continue\n",
        "          source_id = source['identifier']\n",
        "          target_id = target['identifier']\n",
        "          source_label = source['type']\n",
        "          target_label = target['type']\n",
        "          biomedical_relations.append({\n",
        "                \"source_id\": source_id,\n",
        "                \"source_label\": source_label,\n",
        "                \"target_id\": target_id,\n",
        "                \"target_label\": target_label,\n",
        "                \"relationship\": rel_type,\n",
        "                \"pmid\": pmid\n",
        "              })\n",
        "\n",
        "        return biomedical_entities, biomedical_relations, doc\n",
        "\n",
        "    def _merge(self, biomedical_entities: List[dict], biomedical_relations: List[dict]) -> List[Document]:\n",
        "        all_merged_biomedical_entities = {}\n",
        "        all_merged_biomedical_relations = {}\n",
        "        for biomedical_entity in biomedical_entities:\n",
        "          if biomedical_entity['id'] not in all_merged_biomedical_entities:\n",
        "            all_merged_biomedical_entities[biomedical_entity['id']] = biomedical_entity\n",
        "            all_merged_biomedical_entities[biomedical_entity['id']]['alt_names'] = [biomedical_entity['span']]\n",
        "            all_merged_biomedical_entities[biomedical_entity['id']]['pmids'] = [biomedical_entity['pmid']]\n",
        "          else:\n",
        "            _span = biomedical_entity['span']\n",
        "            _pmid = biomedical_entity['pmid']\n",
        "            if _span not in all_merged_biomedical_entities[biomedical_entity['id']]['alt_names']:\n",
        "              all_merged_biomedical_entities[biomedical_entity['id']]['alt_names'].append(_span)\n",
        "\n",
        "            if _pmid not in all_merged_biomedical_entities[biomedical_entity['id']]['pmids']:\n",
        "              all_merged_biomedical_entities[biomedical_entity['id']]['pmids'].append(_pmid)\n",
        "\n",
        "        for biomedical_relation in biomedical_relations:\n",
        "          source_id = biomedical_relation['source_id']\n",
        "          target_id = biomedical_relation['target_id']\n",
        "          source_label = biomedical_relation['source_label']\n",
        "          target_label = biomedical_relation['target_label']\n",
        "          relationship = biomedical_relation['relationship']\n",
        "          _id = f\"{source_label}_{source_id}_{target_label}_{target_id}_{relationship}\"\n",
        "          if _id not in all_merged_biomedical_relations:\n",
        "              all_merged_biomedical_relations[_id] = {\n",
        "                  \"source_id\": source_id,\n",
        "                  \"source_label\": source_label,\n",
        "                  \"target_id\": target_id,\n",
        "                  \"target_label\": target_label,\n",
        "                  \"relationship\": relationship,\n",
        "                  \"pmids\": [biomedical_relation['pmid']]\n",
        "                }\n",
        "          else:\n",
        "              _pmid = biomedical_relation['pmid']\n",
        "              if _pmid not in all_merged_biomedical_relations[_id]['pmids']:\n",
        "                all_merged_biomedical_relations[_id]['pmids'].append(_pmid)\n",
        "\n",
        "        merged_biomedical_entities = list(all_merged_biomedical_entities.values())\n",
        "        merged_biomedical_relations = list(all_merged_biomedical_relations.values())\n",
        "        return merged_biomedical_entities, merged_biomedical_relations\n",
        "\n",
        "    def request_and_parse_pubtator(self, pmids: List[str], pubtator_chunk_size=50):\n",
        "        all_responses = []\n",
        "\n",
        "        # STEP 1: Fetching the PubTator Informations\n",
        "        self.logger.info(\"Fetching PubTator data...\")\n",
        "        for i in tqdm(\n",
        "            range(0, len(pmids), pubtator_chunk_size),\n",
        "            desc=\"Fetching PubTator data\",\n",
        "        ):\n",
        "            chunk = pmids[i : i + pubtator_chunk_size]\n",
        "            try:\n",
        "                response = self._fetch_publications(chunk)\n",
        "                all_responses.append(response)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                self.logger.error(\n",
        "                    f\"Failed to fetch data from PubTator API for chunk {chunk}: {e}\"\n",
        "                )\n",
        "            sleep(0.5)\n",
        "\n",
        "        fetched_ner_re = [doc for pubtator_response in all_responses\n",
        "            for doc in pubtator_response[\"PubTator3\"]\n",
        "        ]\n",
        "        self.logger.info(f\"Fetched {len(fetched_ner_re)} PubTator data.\")\n",
        "\n",
        "        # STEP 2: Parsing the PubTator Identified Biomedical Named Entities and Relations\n",
        "        self.logger.info(\"Parsing PubTator data...\")\n",
        "        biomedical_ner = []\n",
        "        biomedical_re = []\n",
        "        documents_texts = []\n",
        "        for item in tqdm(fetched_ner_re, desc=\"Parsing PubTator data\"):\n",
        "            _biomedical_ner, _biomedical_re, doc = self._parse(item)\n",
        "            biomedical_ner += _biomedical_ner\n",
        "            biomedical_re += _biomedical_re\n",
        "            documents_texts.append(doc)\n",
        "\n",
        "        # STEP 3: Merge Biomedical Entities and Relations\n",
        "        merged_biomedical_entities, merged_biomedical_relations = self._merge(biomedical_ner, biomedical_re)\n",
        "        return merged_biomedical_entities, merged_biomedical_relations, documents_texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting NER and RE from PubTator"
      ],
      "metadata": {
        "id": "aRZi-eKzXZq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pubtator = PubTatorClient(base_url=\"https://www.ncbi.nlm.nih.gov/research/pubtator3-api/publications/export/biocjson\")"
      ],
      "metadata": {
        "id": "v-oeUensPVEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/sampled_documents_pmids.json\", \"r\") as f:\n",
        "    all_pmids = json.load(f)"
      ],
      "metadata": {
        "id": "KK_ywPNtPfhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(f\"There are {len(all_pmids)} pubmed documents.\")"
      ],
      "metadata": {
        "id": "hGiGE5jI6-TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run a sample\n",
        "# pmids = all_pmids[: 100]\n",
        "# or run all\n",
        "pmids = all_pmids"
      ],
      "metadata": {
        "id": "djbmtsWF7G5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_biomedical_entities, merged_biomedical_relations, documents_texts = pubtator.request_and_parse_pubtator(pmids)"
      ],
      "metadata": {
        "id": "tN38Hj8ohYXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to json\n",
        "import json\n",
        "with open(\"merged_biomedical_entities.json\", \"w\") as f:\n",
        "    json.dump(merged_biomedical_entities, f, indent=4)\n",
        "\n",
        "with open(\"merged_biomedical_relations.json\", \"w\") as f:\n",
        "    json.dump(merged_biomedical_relations, f, indent=4)\n",
        "\n",
        "with open(\"documents_texts.json\", \"w\") as f:\n",
        "    json.dump(documents_texts, f,indent=4)"
      ],
      "metadata": {
        "id": "PFzoMPPfknZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Language Model: NER and RE"
      ],
      "metadata": {
        "id": "XhdHMnb_CvPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling LLM with dspy and structured JSON outputs"
      ],
      "metadata": {
        "id": "3p1AE72yXmiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import dspy\n",
        "from enum import Enum\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "\n",
        "# load .env vars\n",
        "_ = load_dotenv(find_dotenv())"
      ],
      "metadata": {
        "id": "6ZbdxuxjC0N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define entity and relation types using Pydantic models\n",
        "class EntityType(str, Enum):\n",
        "    \"\"\"Entity types for biomedical NER\"\"\"\n",
        "    GENE = \"Gene\"\n",
        "    DISEASE = \"Disease\"\n",
        "    CHEMICAL = \"Chemical\"\n",
        "    VARIANT = \"Variant\"\n",
        "    SPECIES = \"Species\"\n",
        "    CELL_LINE = \"Cell Line\"\n",
        "\n",
        "class RelationType(str, Enum):\n",
        "    \"\"\"Relation types for biomedical RE\"\"\"\n",
        "    ASSOCIATE = \"ASSOCIATE\"\n",
        "    CAUSE = \"CAUSE\"\n",
        "    COMPARE = \"COMPARE\"\n",
        "    COTREAT = \"COTREAT\"\n",
        "    DRUG_INTERACT = \"DRUG_INTERACT\"\n",
        "    INHIBIT = \"INHIBIT\"\n",
        "    INTERACT = \"INTERACT\"\n",
        "    NEGATIVE_CORRELATE = \"NEGATIVE_CORRELATE\"\n",
        "    POSITIVE_CORRELATE = \"POSITIVE_CORRELATE\"\n",
        "    PREVENT = \"PREVENT\"\n",
        "    STIMULATE = \"STIMULATE\"\n",
        "    TREAT = \"TREAT\"\n",
        "\n",
        "class Relation(BaseModel):\n",
        "    \"\"\"Represents a relation between two entities\"\"\"\n",
        "    entity1_span: str = Field(description=\"Text span of the first entity\")\n",
        "    entity1_type: EntityType = Field(\n",
        "        description=\"Type of the first entity\"\n",
        "    )\n",
        "    entity2_span: str = Field(description=\"Text span of the second entity\")\n",
        "    entity2_type: EntityType = Field(\n",
        "        description=\"Type of the second entity\"\n",
        "    )\n",
        "    relation_type: RelationType = Field(description=\"Type of relation between entities\")\n",
        "\n",
        "\n",
        "# DSPy signature for biomedical extraction from PubMed abstracts\n",
        "class BiomedicalExtraction(dspy.Signature):\n",
        "    \"\"\"\n",
        "    Extract biomedical entities and their relations from PubMed title and abstract text.\n",
        "    Focus on scientifically relevant entities and relationships commonly found in biomedical literature.\n",
        "\n",
        "    Entity Types with PubMed Context:\n",
        "    - Gene: Protein-coding genes, gene symbols (e.g., BRCA1, TP53), gene families\n",
        "    - Disease: Diseases, disorders, syndromes, pathological conditions from MeSH\n",
        "    - Chemical: Drugs, compounds, metabolites, therapeutic agents from MeSH\n",
        "    - Variant: SNPs (rs numbers), mutations (p.Val600Glu), copy number variants\n",
        "    - Species: Organisms, model systems (Homo sapiens, Mus musculus, etc.)\n",
        "    - Cell Line: Immortalized cell lines, primary cells (HeLa, MCF-7, etc.)\n",
        "\n",
        "    Relation Types for PubMed Literature:\n",
        "    - ASSOCIATE: General biological association or correlation\n",
        "    - CAUSE: Causal relationships, pathogenesis, disease etiology\n",
        "    - COMPARE: Comparative studies, drug comparisons, treatment efficacy\n",
        "    - COTREAT: Combination therapies, drug combinations\n",
        "    - DRUG_INTERACT: Drug-drug interactions, pharmacological interactions\n",
        "    - INHIBIT: Inhibition, suppression, downregulation\n",
        "    - INTERACT: Physical/molecular interactions, binding, complexes\n",
        "    - NEGATIVE_CORRELATE: Inverse correlation, negative association\n",
        "    - POSITIVE_CORRELATE: Positive correlation, co-expression, co-regulation\n",
        "    - PREVENT: Prevention, protective effects, risk reduction\n",
        "    - STIMULATE: Activation, upregulation, enhancement\n",
        "    - TREAT: Therapeutic relationships, treatment efficacy\n",
        "\n",
        "    Instructions:\n",
        "    - Extract entities as they appear in the text (preserve original naming)\n",
        "    - Focus on scientifically meaningful relationships\n",
        "    - Consider both title and abstract content\n",
        "    - Prioritize well-established biomedical relationships\n",
        "    - Handle abbreviations and full names appropriately\n",
        "    - Do NOT integrate novel Relation Types\n",
        "    \"\"\"\n",
        "\n",
        "    pubmed_text: str = dspy.InputField(desc=\"PubMed title and abstract text\")\n",
        "    relations: List[Relation] = dspy.OutputField(desc=\"Extracted biomedical relations\")\n",
        "\n",
        "# Main extraction module\n",
        "class BiomedicalNERRE(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.extract = dspy.Predict(BiomedicalExtraction)\n",
        "\n",
        "    def forward(self, pubmed_text: str, demonstrations: List[dspy.Example] = []) -> List[Relation]:\n",
        "        \"\"\"Extract entities and relations from PubMed title and abstract\"\"\"\n",
        "        result = self.extract(pubmed_text=pubmed_text, demos=demonstrations)\n",
        "        return result.relations\n",
        "\n",
        "# Configuration class for different LLM backends\n",
        "class LLMConfig:\n",
        "    @staticmethod\n",
        "    def setup_openai(api_key: str, model: str = \"gpt-4o-mini\", max_tokens=2048):\n",
        "        \"\"\"Setup OpenAI API\"\"\"\n",
        "        import openai\n",
        "        openai.api_key = api_key\n",
        "        lm = dspy.LM(model, max_tokens=max_tokens)\n",
        "        dspy.configure(lm=lm, adapter=dspy.JSONAdapter())\n",
        "        dspy.settings.lm.kwargs[\"temperature\"] = 0.0\n",
        "        return lm\n",
        "\n",
        "    @staticmethod\n",
        "    def setup_ollama(api_base: str = \"http://127.0.0.1:11434\", model: str = \"llama3.1:8b\", max_tokens=2048):\n",
        "        \"\"\"Setup Ollama local model\"\"\"\n",
        "        lm = dspy.LM(model, api_base=api_base, max_tokens=max_tokens)\n",
        "        dspy.configure(lm=lm, adapter=dspy.JSONAdapter())\n",
        "        dspy.settings.lm.kwargs[\"temperature\"] = 0.0\n",
        "        return lm\n",
        "\n",
        "# Main execution class\n",
        "class BiomedicalExtractor:\n",
        "    def __init__(self, llm_type: str = \"openai\", **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize the biomedical extractor\n",
        "\n",
        "        Args:\n",
        "            llm_type: \"openai\" or \"ollama\"\n",
        "            **kwargs: Additional arguments for LLM setup\n",
        "        \"\"\"\n",
        "        self.llm_type = llm_type\n",
        "\n",
        "        if llm_type == \"openai\":\n",
        "            api_key = kwargs.get(\"api_key\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "            model = kwargs.get(\"model\", \"gpt-4-turbo-preview\")\n",
        "            self.lm = LLMConfig.setup_openai(api_key, model)\n",
        "        elif llm_type == \"ollama\":\n",
        "            model = kwargs.get(\"model\", \"llama3.1:8b\")\n",
        "            base_url = kwargs.get(\"base_url\", \"http://127.0.0.1:11434\")\n",
        "            print(f\"model: {model} / base_url: {base_url}\")\n",
        "            self.lm = LLMConfig.setup_ollama(base_url, model)\n",
        "\n",
        "        # Initialize extractor\n",
        "        self.extractor = BiomedicalNERRE()\n",
        "\n",
        "    def extract(self, pubmed_text: str, demonstrations=[]) -> List[Relation]:\n",
        "        \"\"\"Extract entities and relations from PubMed text\"\"\"\n",
        "        try:\n",
        "            result = self.extractor(pubmed_text, demonstrations=demonstrations)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Extraction failed: {e}\")\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "VeIuvN-fOOcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SOME DEMONSTRATIONS\n",
        "# PubMed-specific demonstration examples\n",
        "PUBMED_EXAMPLES = [\n",
        "    {\n",
        "        \"pubmed_text\": \"Bimekizumab: The First Dual Inhibitor of Interleukin (IL)-17A and IL-17F for the Treatment of Psoriatic Disease and Ankylosing Spondylitis. Psoriasis is a chronic inflammatory skin disease with significant psychological and physical impact. Over the last few decades, several highly effective target therapies have been developed, leading to a major paradigm shift in the way psoriatic disease is managed. Despite this, a proportion of patients still do not respond or lose response over time. Bispecific antibodies target two different cytokines simultaneously, potentially offering a better disease control. Interleukin (IL)-17A and IL-17F share structural homology and have similar biologic function. IL-17A is classically considered to be the most biologically active, but recent studies have shown that IL-17F is also increased in psoriatic skin and synovial cell in psoriatic arthritis, supporting the rationale for targeting both IL-17A and IL-17F in psoriatic disease. Bimekizumab is the first-in-class monoclonal antibody designed to simultaneously target IL-17A and IL-17F. Bimekizumab is currently in clinical development for psoriasis, psoriatic arthritis, and ankylosing spondylitis, with promising results. In early clinical trials, bimekizumab demonstrated a rapid onset of action, good safety profile, and high tolerability by treated study participants. Long-term results and head-to-head trials comparing bimekizumab with other agents will be crucial to define the role of bimekizumab in the treatment of psoriatic disease.\",\n",
        "        \"relations\": [\n",
        "            Relation(\n",
        "                entity1_span=\"IL-17A\", entity1_type=\"Gene\",\n",
        "                entity2_span=\"Psoriatic Disease\", entity2_type=\"Disease\",\n",
        "                relation_type=\"ASSOCIATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"IL-17F\", entity1_type=\"Gene\",\n",
        "                entity2_span=\"Psoriatic Disease\", entity2_type=\"Disease\",\n",
        "                relation_type=\"ASSOCIATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"IL-17A\", entity1_type=\"Gene\",\n",
        "                entity2_span=\"Ankylosing Spondylitis\", entity2_type=\"Disease\",\n",
        "                relation_type=\"ASSOCIATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"IL-17F\", entity1_type=\"Gene\",\n",
        "                entity2_span=\"Ankylosing Spondylitis\", entity2_type=\"Disease\",\n",
        "                relation_type=\"ASSOCIATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"bimekizumab\", entity1_type=\"Chemical\",\n",
        "                entity2_span=\"IL-17A\", entity2_type=\"Gene\",\n",
        "                relation_type=\"NEGATIVE_CORRELATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"bimekizumab\", entity1_type=\"Chemical\",\n",
        "                entity2_span=\"IL-17F\", entity2_type=\"Gene\",\n",
        "                relation_type=\"NEGATIVE_CORRELATE\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"bimekizumab\", entity1_type=\"Chemical\",\n",
        "                entity2_span=\"psoriasis\", entity2_type=\"Disease\",\n",
        "                relation_type=\"TREAT\"\n",
        "            ),\n",
        "            Relation(\n",
        "                entity1_span=\"bimekizumab\", entity1_type=\"Chemical\",\n",
        "                entity2_span=\"psoriatic arthritis\", entity2_type=\"Disease\",\n",
        "                relation_type=\"TREAT\"\n",
        "            ),\n",
        "\n",
        "            Relation(\n",
        "                entity1_span=\"bimekizumab\", entity1_type=\"Chemical\",\n",
        "                entity2_span=\"ankylosing spondylitis\", entity2_type=\"Disease\",\n",
        "                relation_type=\"TREAT\"\n",
        "            )\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"pubmed_text\": \"Molecular dynamics and protein frustration analysis of human fused in Sarcoma protein variants in Amyotrophic Lateral Sclerosis type 6: An In Silico approach. Amyotrophic lateral sclerosis (ALS) is the most frequent adult-onset motor neuron disorder. The disease is characterized by degeneration of upper and lower motor neurons, leading to death usually within five years after the onset of symptoms. While most cases are sporadic, 5%-10% of cases can be associated with familial inheritance, including ALS type 6, which is associated with mutations in the Fused in Sarcoma (FUS) gene. This work aimed to evaluate how the most frequent ALS-related mutations in FUS, R521C, R521H, and P525L affect the protein structure and function. We used prediction algorithms to analyze the effects of the non-synonymous single nucleotide polymorphisms and performed evolutionary conservation analysis, protein frustration analysis, and molecular dynamics simulations. Most of the prediction algorithms classified the three mutations as deleterious. All three mutations were predicted to reduce protein stability, especially the mutation R521C, which was also predicted to increase chaperone binding tendency. The protein frustration analysis showed an increase in frustration in the interactions involving the mutated residue 521C. Evolutionary conservation analysis showed that residues 521 and 525 of human FUS are highly conserved sites. The molecular dynamics results indicate that protein stability could be compromised in all three mutations. They also affected the exposed surface area and protein compactness. The analyzed mutations also displayed high flexibility in most residues in all variants, most notably in the interaction site with the nuclear import protein of FUS.\",\n",
        "        \"relations\": [\n",
        "                Relation(\n",
        "                    entity1_span=\"Amyotrophic lateral sclerosis\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"Fused in Sarcoma\", entity2_type=\"Gene\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"Amyotrophic lateral sclerosis\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"p.R521C_FUS\", entity2_type=\"Variant\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"Amyotrophic lateral sclerosis\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"p.R521H_FUS\", entity2_type=\"Variant\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"Amyotrophic lateral sclerosis\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"p.P525L_FUS\", entity2_type=\"Variant\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                )\n",
        "            ]\n",
        "    },\n",
        "    {\n",
        "        \"pubmed_text\": \"Management of infusion-related reactions (IRRs) in patients receiving amivantamab in the CHRYSALIS study. BACKGROUND: Amivantamab, a fully humanized EGFR-MET bispecific antibody, has antitumor activity in diverse EGFR- and MET-driven non-small cell lung cancer (NSCLC) and a safety profile consistent with associated on-target activities. Infusion-related reaction(s) (IRR[s]) are reported commonly with amivantamab. We review IRR and subsequent management in amivantamab-treated patients. METHODS: Patients treated with the approved dose of intravenous amivantamab (1050 mg, <80 kg; 1400 mg, >=80 kg) in CHRYSALIS-an ongoing, phase 1 study in advanced EGFR-mutated NSCLC-were included in this analysis. IRR mitigations included split first dose (350 mg, day 1 [D1]; remainder, D2), reduced initial infusion rates with proactive infusion interruption, and steroid premedication before initial dose. For all doses, pre-infusion antihistamines and antipyretics were required. Steroids were optional after the initial dose. RESULTS: As of 3/30/2021, 380 patients received amivantamab. IRRs were reported in 256 (67%) patients. Signs/symptoms of IRR included chills, dyspnea, flushing, nausea, chest discomfort, and vomiting. Most of the 279 IRRs were grade 1 or 2; grade 3 and 4 IRR occurred in 7 and 1 patients, respectively. Most (90%) IRRs occurred on cycle 1, D1 (C1D1); median time-to-first-IRR onset during C1D1 was 60 min; and first-infusion IRRs did not compromise subsequent infusions. Per protocol, IRR was mitigated on C1D1 with holding of infusion (56% [214/380]), reinitiating at reduced rate (53% [202/380]), and aborting infusion (14% [53/380]). C1D2 infusions were completed in 85% (45/53) of patients who had C1D1 infusions aborted. Four patients (1% [4/380]) discontinued treatment due to IRR. In studies aimed at elucidating the underlying mechanism(s) of IRR, no pattern was observed between patients with versus without IRR. CONCLUSION: IRRs with amivantamab were predominantly low grade and limited to first infusion, and rarely occurred with subsequent dosing. Close monitoring for IRR with the initial amivantamab dose and early intervention at first IRR signs/symptoms should be part of routine amivantamab administration.\",\n",
        "        \"relations\": [\n",
        "                Relation(\n",
        "                    entity1_span=\"non-small cell lung cancer\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"EGFR\", entity2_type=\"Gene\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"non-small cell lung cancer\", entity1_type=\"Disease\",\n",
        "                    entity2_span=\"SLTM\", entity2_type=\"Gene\",\n",
        "                    relation_type=\"ASSOCIATE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"Chills\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"Dyspnea\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"Flushing\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"nausea\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"nausea\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"chest discomfort\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"vomiting\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"CAUSE\"\n",
        "                ),\n",
        "                Relation(\n",
        "                    entity1_span=\"amivantamab\", entity1_type=\"Chemical\",\n",
        "                    entity2_span=\"non-small cell lung cancer\", entity2_type=\"Disease\",\n",
        "                    relation_type=\"TREAT\"\n",
        "                )\n",
        "            ]\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "jc_7QgGsO80y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An example with OpenAI GPT-4o-mini"
      ],
      "metadata": {
        "id": "hai06SuoXr-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_openai = BiomedicalExtractor(\n",
        "    llm_type=\"openai\",\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "# Test with PubMed-style abstract\n",
        "pubmed_text = \"PCOS is an endocrine disorder characterized by chronic anovulation, hyperandrogenism, and polycystic ovaries. Its etiology is uncertain. It is debated whether BPA would be a component of the environmental factor in the etiology of PCOS. Contamination by BPA can occur from food packaging (exposure during the diet) and through skin absorption and/or inhalation. It can be transferred to the fetus via the placenta or to the infant via breast milk, and it can be found in follicular fluid, fetal serum, and amniotic fluid. The phenolic structure of BPA allows it to interact with Estrogen Receptors (ERs) through genomic signaling, in which BPA binds to nuclear ERalpha or Erbeta, or through nongenomic signaling by binding to membrane ERs, prompting a rapid and intense response. With daily and constant exposure, BPA's tendency to bioaccumulate and its ability to activate nongenomic signaling pathways can alter women's metabolic and reproductive function, leading to hyperandrogenism, insulin resistance, obesity, atherogenic dyslipidemia, chronic inflammatory state, and anovulation and favoring PCOS. The harmful changes caused by BPA can be passed on to future generations without the need for additional exposure because of epigenetic modifications. Not only high BPA levels can produce harmful effects, but at low levels, BPA may be harmful when exposure occurs during the most vulnerable periods, such as the fetal and neonatal periods, as well as during the prepubertal age causing an early accumulation of BPA in the body. Learning how BPA participates in the pathogenesis of PCOS poses a challenge and further studies should be conducted.\"\n",
        "\n",
        "result = extractor_openai.extract(pubmed_text, demonstrations=PUBMED_EXAMPLES)\n"
      ],
      "metadata": {
        "id": "pGybBcLYRgIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "XID7abuxR4Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using local models (with ollama)"
      ],
      "metadata": {
        "id": "vA05jsOJbJVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing ollama"
      ],
      "metadata": {
        "id": "6LI6pxSeXz4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! sudo apt update && sudo apt install pciutils lshw\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "5NUX6S1ebK45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.log 2>&1 &"
      ],
      "metadata": {
        "id": "WjTm-UaOb7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ollama run llama3.1:8b “What is the capital of the Netherlands?”"
      ],
      "metadata": {
        "id": "WdTRLO04b4ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An example with LLama 3.1:8b"
      ],
      "metadata": {
        "id": "odtKwunJX4ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_openai = BiomedicalExtractor(\n",
        "    llm_type=\"ollama\",\n",
        "    model=\"ollama_chat/llama3.1:8b\",\n",
        "    base_url=\"http://127.0.0.1:11434\"\n",
        ")\n",
        "\n",
        "# Test with PubMed-style abstract\n",
        "pubmed_text = \"Does bisphenol A (BPA) participates in the pathogenesis of Polycystic Ovary Syndrome (PCOS)? PCOS is an endocrine disorder characterized by chronic anovulation, hyperandrogenism, and polycystic ovaries. Its etiology is uncertain. It is debated whether BPA would be a component of the environmental factor in the etiology of PCOS. Contamination by BPA can occur from food packaging (exposure during the diet) and through skin absorption and/or inhalation. It can be transferred to the fetus via the placenta or to the infant via breast milk, and it can be found in follicular fluid, fetal serum, and amniotic fluid. The phenolic structure of BPA allows it to interact with Estrogen Receptors (ERs) through genomic signaling, in which BPA binds to nuclear ERalpha or Erbeta, or through nongenomic signaling by binding to membrane ERs, prompting a rapid and intense response. With daily and constant exposure, BPA's tendency to bioaccumulate and its ability to activate nongenomic signaling pathways can alter women's metabolic and reproductive function, leading to hyperandrogenism, insulin resistance, obesity, atherogenic dyslipidemia, chronic inflammatory state, and anovulation and favoring PCOS. The harmful changes caused by BPA can be passed on to future generations without the need for additional exposure because of epigenetic modifications. Not only high BPA levels can produce harmful effects, but at low levels, BPA may be harmful when exposure occurs during the most vulnerable periods, such as the fetal and neonatal periods, as well as during the prepubertal age causing an early accumulation of BPA in the body. Learning how BPA participates in the pathogenesis of PCOS poses a challenge and further studies should be conducted.\"\n",
        "\n",
        "result = extractor_openai.extract(pubmed_text, demonstrations=PUBMED_EXAMPLES)"
      ],
      "metadata": {
        "id": "mIOvM-CtcTdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AXlQoIFHdXAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's compare some examples\n",
        "\n",
        "Let's take a first example of PMID 38008036."
      ],
      "metadata": {
        "id": "Ek2gJSN9w68j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils methods for comparison"
      ],
      "metadata": {
        "id": "0guxw1geBiW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib_venn import venn2, venn2_circles\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Set, Tuple, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages if not already installed\n",
        "# !pip install matplotlib-venn seaborn pandas matplotlib\n",
        "\n",
        "class BiomedicalnteractionComparison:\n",
        "    \"\"\"\n",
        "    Simplified tool for 1-vs-1 comparison of biomedical NER/RE methods\n",
        "    Uses a common format with entity spans as lists to handle multiple possible spans\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def convert_pubtator_to_common_format(self, pubtator_relations: List[Dict],\n",
        "                                        pubtator_entities: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Convert PubTator results to common format\n",
        "\n",
        "        Args:\n",
        "            pubtator_relations: List of PubTator relations with IDs\n",
        "            pubtator_entities: List of PubTator entities with spans and alt_names\n",
        "\n",
        "        Returns:\n",
        "            List of relations in common format with entity spans as lists\n",
        "        \"\"\"\n",
        "        # Create mapping from entity ID to all possible spans\n",
        "        id_to_spans = {}\n",
        "        for entity in pubtator_entities:\n",
        "            entity_id = entity['id']\n",
        "            spans = [entity['span'], entity['name']]\n",
        "            if 'alt_names' in entity:\n",
        "                spans.extend(entity['alt_names'])\n",
        "            # Remove duplicates and empty strings, keep original casing\n",
        "            unique_spans = list(set([span.strip() for span in spans if span and span.strip()]))\n",
        "            id_to_spans[entity_id] = unique_spans\n",
        "\n",
        "        # Convert relations\n",
        "        common_format_relations = []\n",
        "        for relation in pubtator_relations:\n",
        "            source_id = relation['source_id']\n",
        "            target_id = relation['target_id']\n",
        "\n",
        "            # Get all possible spans for entities\n",
        "            entity1_spans = id_to_spans.get(source_id, [])\n",
        "            entity2_spans = id_to_spans.get(target_id, [])\n",
        "\n",
        "            if entity1_spans and entity2_spans:  # Only add if we have spans for both entities\n",
        "                common_relation = {\n",
        "                    \"entity1_span\": entity1_spans,\n",
        "                    \"entity1_type\": relation['source_label'],\n",
        "                    \"entity2_span\": entity2_spans,\n",
        "                    \"entity2_type\": relation['target_label'],\n",
        "                    \"relation_type\": relation['relationship'].lower()  # Normalize to lowercase\n",
        "                }\n",
        "                common_format_relations.append(common_relation)\n",
        "\n",
        "        return common_format_relations\n",
        "\n",
        "    def convert_llm_to_common_format(self, llm_relations: List) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Convert LLM results to common format\n",
        "\n",
        "        Args:\n",
        "            llm_relations: List of LLM relations (Pydantic objects or dicts)\n",
        "\n",
        "        Returns:\n",
        "            List of relations in common format with entity spans as single-item lists\n",
        "        \"\"\"\n",
        "        common_format_relations = []\n",
        "\n",
        "        for relation in llm_relations:\n",
        "            # Handle different possible formats\n",
        "            if hasattr(relation, 'entity1_span'):\n",
        "                # Pydantic model format\n",
        "                e1_span = relation.entity1_span\n",
        "                e1_type = relation.entity1_type if isinstance(relation.entity1_type, str) else relation.entity1_type.value\n",
        "                e2_span = relation.entity2_span\n",
        "                e2_type = relation.entity2_type if isinstance(relation.entity2_type, str) else relation.entity2_type.value\n",
        "                rel_type = relation.relation_type if isinstance(relation.relation_type, str) else relation.relation_type.value\n",
        "            else:\n",
        "                # Dictionary format\n",
        "                e1_span = relation['entity1_span']\n",
        "                e1_type = relation['entity1_type']\n",
        "                e2_span = relation['entity2_span']\n",
        "                e2_type = relation['entity2_type']\n",
        "                rel_type = relation['relation_type']\n",
        "\n",
        "            common_relation = {\n",
        "                \"entity1_span\": [e1_span.strip()],  # Single span in list format\n",
        "                \"entity1_type\": e1_type.strip(),\n",
        "                \"entity2_span\": [e2_span.strip()],  # Single span in list format\n",
        "                \"entity2_type\": e2_type.strip(),\n",
        "                \"relation_type\": rel_type.lower().strip()  # Normalize to lowercase\n",
        "            }\n",
        "            common_format_relations.append(common_relation)\n",
        "\n",
        "        return common_format_relations\n",
        "\n",
        "    def normalize_relation(self, rel):\n",
        "        \"\"\"Convert relation dict into a normalized tuple so it can be compared.\"\"\"\n",
        "        return (\n",
        "            tuple(rel['entity1_span']),  # keep all aliases\n",
        "            rel['entity1_type'],\n",
        "            tuple(rel['entity2_span']),\n",
        "            rel['entity2_type'],\n",
        "            rel['relation_type']\n",
        "        )\n",
        "\n",
        "    def match_relations(self, pubtator_list, llm_list):\n",
        "        common = []\n",
        "        pub_unique = []\n",
        "        llm_unique = []\n",
        "\n",
        "        matched_llm_indices = set()\n",
        "\n",
        "        for i, rel1 in enumerate(pubtator_list):\n",
        "            found_match = False\n",
        "            for j, rel2 in enumerate(llm_list):\n",
        "                # Check entity1 spans\n",
        "                e1_match = any(span1.lower() == span2.lower()\n",
        "                  for span1 in rel1['entity1_span']\n",
        "                  for span2 in rel2['entity1_span'])\n",
        "                e2_match = any(span1.lower() == span2.lower()\n",
        "                              for span1 in rel1['entity2_span']\n",
        "                              for span2 in rel2['entity2_span'])\n",
        "                # Check types and relation\n",
        "                type_match = (rel1['entity1_type'] == rel2['entity1_type']\n",
        "                              and rel1['entity2_type'] == rel2['entity2_type'])\n",
        "                relation_match = rel1['relation_type'] == rel2['relation_type']\n",
        "\n",
        "                if e1_match and e2_match and type_match and relation_match:\n",
        "                    common.append((rel1, rel2))\n",
        "                    matched_llm_indices.add(j)\n",
        "                    found_match = True\n",
        "                    break\n",
        "            if not found_match:\n",
        "                pub_unique.append(rel1)\n",
        "\n",
        "        # LLM uniques\n",
        "        for j, rel2 in enumerate(llm_list):\n",
        "            if j not in matched_llm_indices:\n",
        "                llm_unique.append(rel2)\n",
        "\n",
        "        return common, pub_unique, llm_unique\n",
        "\n",
        "\n",
        "    def plot_venn(self, pub_unique, llm_unique, common):\n",
        "        plt.figure(figsize=(6,6))\n",
        "        venn2(subsets=(len(pub_unique), len(llm_unique), len(common)),\n",
        "              set_labels=('PubTator', 'LLM'))\n",
        "        plt.title(\"Relation Overlap\")\n",
        "        plt.show()\n",
        "\n",
        "    def print_relations(self, common, pub_unique, llm_unique):\n",
        "        def format_rel(rel):\n",
        "            e1 = \"(\" + \"; \".join(rel['entity1_span']) + \")\"\n",
        "            e2 = \"(\" + \"; \".join(rel['entity2_span']) + \")\"\n",
        "            return f\"[{rel['entity1_type']}] {e1}  --{rel['relation_type']}-->  [{rel['entity2_type']}] {e2}\"\n",
        "\n",
        "        print(\"\\n=== Common Relations ===\")\n",
        "        for idx, (p, l) in enumerate(common, 1):\n",
        "            print(f\"{idx}.\")\n",
        "            print(f\"  PubTator: {format_rel(p)}\")\n",
        "            print(f\"  LLM     : {format_rel(l)}\\n\")\n",
        "\n",
        "        print(\"\\n=== Unique to PubTator ===\")\n",
        "        for idx, r in enumerate(pub_unique, 1):\n",
        "            print(f\"{idx}. {format_rel(r)}\")\n",
        "\n",
        "        print(\"\\n=== Unique to LLM ===\")\n",
        "        for idx, r in enumerate(llm_unique, 1):\n",
        "            print(f\"{idx}. {format_rel(r)}\")\n",
        "\n",
        "\n",
        "\n",
        "    def compare(self, result_1, method_1, result_2, method_2):\n",
        "        if method_1 == \"pubtator\":\n",
        "            result_1 = self.convert_pubtator_to_common_format(*result_1)\n",
        "        else:\n",
        "            result_1 = self.convert_llm_to_common_format(result_1)\n",
        "\n",
        "        if method_2 == \"pubtator\":\n",
        "            result_2 = self.convert_pubtator_to_common_format(*result_2)\n",
        "        else:\n",
        "            result_2 = self.convert_llm_to_common_format(result_2)\n",
        "\n",
        "        common, pub_unique, llm_unique = self.match_relations(result_1, result_2)\n",
        "\n",
        "        self.print_relations(common, pub_unique, llm_unique)\n",
        "\n",
        "        self.plot_venn(pub_unique, llm_unique, common)\n"
      ],
      "metadata": {
        "id": "AFKnH4T-BoKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run comparison"
      ],
      "metadata": {
        "id": "9mkhLtkpBs7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's choose a pmid. For instance the article \"Does bisphenol A (BPA) participates in the pathogenesis of Polycystic Ovary Syndrome (PCOS)?\" (PMID: 38008036)\n",
        "selected_pmid = [\"38008036\"]\n",
        "\n",
        "# Or even a random one:\n",
        "selected_pmid = [random.choice(all_pmids)]"
      ],
      "metadata": {
        "id": "J66VoYoFCXmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Selected PMID: {selected_pmid}\")"
      ],
      "metadata": {
        "id": "QjgCMjz6D9X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use PubTator (classic NER) - small models and scalable.\n",
        "entities_pubtator, relations_pubtator, doc_text = pubtator.request_and_parse_pubtator(selected_pmid)"
      ],
      "metadata": {
        "id": "au1ug984w6jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We then use the extracted text to call OpenAI and Ollama models\n",
        "extractor_openai = BiomedicalExtractor(\n",
        "    llm_type=\"openai\",\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "\n",
        "result_openai = extractor_openai.extract(doc_text[0], demonstrations=PUBMED_EXAMPLES)"
      ],
      "metadata": {
        "id": "HrOHdPUOxhfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_openai = BiomedicalExtractor(\n",
        "    llm_type=\"ollama\",\n",
        "    model=\"ollama_chat/llama3.1:8b\",\n",
        "    base_url=\"http://127.0.0.1:11434\"\n",
        ")\n",
        "\n",
        "result_llama = extractor_openai.extract(doc_text[0], demonstrations=PUBMED_EXAMPLES)"
      ],
      "metadata": {
        "id": "yVDsdf68x1tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the comparator\n",
        "comparator = BiomedicalnteractionComparison()"
      ],
      "metadata": {
        "id": "sMlMln6y1s5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare !\n",
        "comparator.compare((relations_pubtator, entities_pubtator), \"pubtator\", result_llama, \"llama\")"
      ],
      "metadata": {
        "id": "gG4G7_w6AU93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What about GPT-4o-mini vs Ollama ?\n",
        "comparator.compare(result_llama, \"llama\", result_openai, \"openai\")"
      ],
      "metadata": {
        "id": "PLwSrinQBSpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More on the comparison\n",
        "\n",
        "[*Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again*](https://doi.org/10.18653/v1/2022.findings-emnlp.329)\n",
        "\n",
        "[*Improving large language models for clinical named entity recognition via prompt engineering*](https://doi.org/10.1093/jamia/ocad259)\n",
        "\n",
        "[*Advancing entity recognition in biomedicine via instruction tuning of large language models*](https://doi.org/10.1093/bioinformatics/btae163)\n",
        "\n",
        "[*LLMs in Biomedicine: A study on clinical Named Entity Recognition*](https://doi.org/10.48550/arXiv.2404.07376)\n",
        "\n",
        "[*Do LLMs Surpass Encoders for Biomedical NER?*](https://doi.org/10.48550/arXiv.2504.00664)\n",
        "\n",
        "[*On-the-fly Definition Augmentation of LLMs for Biomedical NER*](https://doi.org/10.18653/v1/2024.naacl-long.212)\n",
        "\n",
        "[*LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction*](https://doi.org/10.18653/v1/2025.insights-1.11)"
      ],
      "metadata": {
        "id": "g8tcOhhRYS6E"
      }
    }
  ]
}